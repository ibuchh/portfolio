{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome! I'm currently a student at the University of Minnesota pursuing a B.S. and M.S. of Computer Science. Interested in robotics, machine learning, artificial intelligence, graph databases, and rapid prototyping. Passionate about mentoring kids in their programming endeavours through CoderDojo Twin Cities. As an Eagle Scout, I've had experience working with and leading teams. Skills Python \u2022 C/C++ \u2022 Machine Learning \u2022 Git \u2022 Spark \u2022 Java \u2022 Go \u2022 Graph Databases \u2022 Docker \u2022 Gradle \u2022 OCaml \u2022 SQL \u2022 Microsoft Office \u2022 Technical Writing \u2022 UNIX Bash scripting \u2022 R \u2022 HTML and CSS \u2022 AWS/Cloud Computing \u2022 3D printing Education B.S. of Computer Science \u2022 University of Minnesota Twin Cities \u2022 Class of 2021 3.8 GPA. Dean\u2019s List. A year ahead in coursework. Participate in Jazz Band and Pep Band. Courses taken include Data Science II, Algorithms and Data Structures, Intro to Statistics, and Intro to Operating Systems. M.S. of Computer Science \u2022 University of Minnesota Twin Cities \u2022 Class of 2022 Will take graduate-level classes starting in the Spring of 2021. Diploma with Highest Honors \u2022 Robbinsdale Armstrong High School \u2022 Class of 2018 4.0/4.0 GPA. AP Scholar Award in 2017 and 2018. Quiz Bowl Captain. Alto Saxophone Section Leader in Marching Band. Participated in Jazz Band, Pep Band, Marching Band, Pit Orchestra, and on the Varsity Tennis team. Experience Software Engineering Intern \u2022 Optum, A UnitedHealth Group Company \u2022 Summer 2020 Developed a documentation and demonstration site for an internal de-identification tool. Software Engineering Intern \u2022 Optum, A UnitedHealth Group Company \u2022 Summer 2019 Developed a financial and claims fraud detection system using a graph convolutional neural network and graph database technology. The solution developed is currently in the patenting process. Mentor \u2022 CoderDojo Twin Cities \u2022 2014 - Present Coaches and inspires kids to create projects using programming and electronics through single board computers and microcontrollers such as the Raspberry Pi and Arduino. Eagle Scout \u2022 October 2015 Developed communication and leadership skills through the planning and execution of Troop activities. Retail Sales Specialist \u2022 REI Co-Op \u2022 2016 - Present Provide excellent customer service through good communication and teamwork with my coworkers. Contact Interested in working together? Contact me at: parker.erickson30@gmail.com 763-202-3059","title":"Home"},{"location":"#welcome","text":"I'm currently a student at the University of Minnesota pursuing a B.S. and M.S. of Computer Science. Interested in robotics, machine learning, artificial intelligence, graph databases, and rapid prototyping. Passionate about mentoring kids in their programming endeavours through CoderDojo Twin Cities. As an Eagle Scout, I've had experience working with and leading teams.","title":"Welcome!"},{"location":"#skills","text":"Python \u2022 C/C++ \u2022 Machine Learning \u2022 Git \u2022 Spark \u2022 Java \u2022 Go \u2022 Graph Databases \u2022 Docker \u2022 Gradle \u2022 OCaml \u2022 SQL \u2022 Microsoft Office \u2022 Technical Writing \u2022 UNIX Bash scripting \u2022 R \u2022 HTML and CSS \u2022 AWS/Cloud Computing \u2022 3D printing","title":"Skills"},{"location":"#education","text":"","title":"Education"},{"location":"#bs-of-computer-science-university-of-minnesota-twin-cities-class-of-2021","text":"3.8 GPA. Dean\u2019s List. A year ahead in coursework. Participate in Jazz Band and Pep Band. Courses taken include Data Science II, Algorithms and Data Structures, Intro to Statistics, and Intro to Operating Systems.","title":"B.S. of Computer Science \u2022 University of Minnesota Twin Cities \u2022 Class of 2021"},{"location":"#ms-of-computer-science-university-of-minnesota-twin-cities-class-of-2022","text":"Will take graduate-level classes starting in the Spring of 2021.","title":"M.S. of Computer Science \u2022 University of Minnesota Twin Cities \u2022 Class of 2022"},{"location":"#diploma-with-highest-honors-robbinsdale-armstrong-high-school-class-of-2018","text":"4.0/4.0 GPA. AP Scholar Award in 2017 and 2018. Quiz Bowl Captain. Alto Saxophone Section Leader in Marching Band. Participated in Jazz Band, Pep Band, Marching Band, Pit Orchestra, and on the Varsity Tennis team.","title":"Diploma with Highest Honors \u2022 Robbinsdale Armstrong High School \u2022 Class of 2018"},{"location":"#experience","text":"","title":"Experience"},{"location":"#software-engineering-intern-optum-a-unitedhealth-group-company-summer-2020","text":"Developed a documentation and demonstration site for an internal de-identification tool.","title":"Software Engineering Intern \u2022 Optum, A UnitedHealth Group Company \u2022 Summer 2020"},{"location":"#software-engineering-intern-optum-a-unitedhealth-group-company-summer-2019","text":"Developed a financial and claims fraud detection system using a graph convolutional neural network and graph database technology. The solution developed is currently in the patenting process.","title":"Software Engineering Intern \u2022 Optum, A UnitedHealth Group Company \u2022 Summer 2019"},{"location":"#mentor-coderdojo-twin-cities-2014-present","text":"Coaches and inspires kids to create projects using programming and electronics through single board computers and microcontrollers such as the Raspberry Pi and Arduino.","title":"Mentor \u2022 CoderDojo Twin Cities \u2022 2014 - Present"},{"location":"#eagle-scout-october-2015","text":"Developed communication and leadership skills through the planning and execution of Troop activities.","title":"Eagle Scout \u2022 October 2015"},{"location":"#retail-sales-specialist-rei-co-op-2016-present","text":"Provide excellent customer service through good communication and teamwork with my coworkers.","title":"Retail Sales Specialist \u2022 REI Co-Op \u2022 2016 - Present"},{"location":"#contact","text":"Interested in working together? Contact me at: parker.erickson30@gmail.com 763-202-3059","title":"Contact"},{"location":"projects/","text":"Baseball Pitch Prediction Using various machine learning methods, I was able to predict the next pitch of an at-bat with up to 75% accuracy. Check out the blog post here pyTigerGraph A Python package that interfaces with a TigerGraph database's REST API. More information can be found here . AI Racing League Created and tested a variety of computer vision algorithms to autonomously control an RC Car. Also teach AI concepts to kids at CoderDojo. IPO Prediction using Graph Convolutional Neural Networks Used TigerGraph Cloud, Gradle, and pyTigerGraph to predict companies that would IPO using Graph Convolutional Neural Networks. Check out the blog post here @mlstyletransfer A Twitter bot that uses machine learning to transfer a certain style of art onto an user-provided photo. Hosted on AWS services. Uses Keras, Python, SQL, HTML, and CSS. The code for the style transfer is here . The code that handles collecting the tweets and inserting them into the database is here . Want to check out some of the results? Check out the gallery .","title":"Projects"},{"location":"projects/#baseball-pitch-prediction","text":"Using various machine learning methods, I was able to predict the next pitch of an at-bat with up to 75% accuracy. Check out the blog post here","title":"Baseball Pitch Prediction"},{"location":"projects/#pytigergraph","text":"A Python package that interfaces with a TigerGraph database's REST API. More information can be found here .","title":"pyTigerGraph"},{"location":"projects/#ai-racing-league","text":"Created and tested a variety of computer vision algorithms to autonomously control an RC Car. Also teach AI concepts to kids at CoderDojo.","title":"AI Racing League"},{"location":"projects/#ipo-prediction-using-graph-convolutional-neural-networks","text":"Used TigerGraph Cloud, Gradle, and pyTigerGraph to predict companies that would IPO using Graph Convolutional Neural Networks. Check out the blog post here","title":"IPO Prediction using Graph Convolutional Neural Networks"},{"location":"projects/#mlstyletransfer","text":"A Twitter bot that uses machine learning to transfer a certain style of art onto an user-provided photo. Hosted on AWS services. Uses Keras, Python, SQL, HTML, and CSS. The code for the style transfer is here . The code that handles collecting the tweets and inserting them into the database is here . Want to check out some of the results? Check out the gallery .","title":"@mlstyletransfer"},{"location":"blog/MkDocsCD/","text":"Continuous Deployment for MkDocs with GitHub Actions June 20, 2020 MkDocs is a great documentation tool, but every time you make an update, there needs to be a deployment process in order to get your updates published to GitHub Pages. To fix this, I decided to learn how to use GitHub actions to automatically update the published site when an update is pushed or merged into the master branch. If you are new to MkDocs, I certainly recommend my previous blog Getting Started with MkDocs What are GitHub Actions? GitHub Actions are a CI/CD tool that is tied directly into GitHub's ecosystem. This allows you to set up workflows that can be triggered through many different events that might take place in your repository, such as a merge or push to a specific branch. In this case, we will trigger the generation and deployment of documentation through MkDocs on every push and merge into the master branch. There are also many pre-built actions available here . The Action All GitHub Actions are defined using YAML. There are two main parts that needs to be defined, consisting of when the action should run, and then what should occur when the action is triggered. To start out, lets create a .github directory in the outermost directory of your repository, followed by a workflows directory within the .github one. Then create a main.yml file, which is where the action will be defined. When to Run The Action I am using this action to update my personal portfolio site as well as some other repositories that only hold documentation and GitHub Pages content. Therefore, I want this action to update with any push or pull request into the master branch. We define this with the following: on: push: branches: [master] pull_request: branches: [master] Defining The Jobs and Steps After we decide when we want GitHub to run the action, the next step is to define the jobs and steps that need to occur in each job. For this, we will only have one job, called build. The tasks will be as follows: Checkout the master branch - this uses a built-in action available to all GitHub Actions to clone the repository into the newly spun-up container. Setup Python 3.7 - this also uses a built-in action that is available to all GitHub Actions. Install pip and mkdocs-material - the run keyword is used for terminal commands that you wish to use. the pip install mkdocs-material also automatically installs mkdocs and any other package dependencies needed. Run mkdocs gh-deploy - this builds the files and deploys them to GitHub pages. The full result can be seen below: name: Build Documentation using MkDocs # Controls when the action will run. Triggers the workflow on push or pull request # events but only for the master branch on: push: branches: [master] pull_request: branches: [master] jobs: build: name: Build and Deploy Documentation runs-on: ubuntu-latest steps: - name: Checkout Master uses: actions/checkout@v2 - name: Set up Python 3.7 uses: actions/setup-python@v2 with: python-version: '3.x' - name: Install dependencies run: | python -m pip install --upgrade pip pip install mkdocs-material - name: Deploy run: | git pull mkdocs gh-deploy Conclusion After creating the file above in the .github/workflows directory, that should be it! Simply commit your changes locally and push to the GitHub repository. You can view the status of the build on the Actions tab on your repository's GitHub page.","title":"Continuous Deployment for MkDocs with GitHub Actions"},{"location":"blog/MkDocsCD/#continuous-deployment-for-mkdocs-with-github-actions","text":"June 20, 2020 MkDocs is a great documentation tool, but every time you make an update, there needs to be a deployment process in order to get your updates published to GitHub Pages. To fix this, I decided to learn how to use GitHub actions to automatically update the published site when an update is pushed or merged into the master branch. If you are new to MkDocs, I certainly recommend my previous blog Getting Started with MkDocs","title":"Continuous Deployment for MkDocs with GitHub Actions"},{"location":"blog/MkDocsCD/#what-are-github-actions","text":"GitHub Actions are a CI/CD tool that is tied directly into GitHub's ecosystem. This allows you to set up workflows that can be triggered through many different events that might take place in your repository, such as a merge or push to a specific branch. In this case, we will trigger the generation and deployment of documentation through MkDocs on every push and merge into the master branch. There are also many pre-built actions available here .","title":"What are GitHub Actions?"},{"location":"blog/MkDocsCD/#the-action","text":"All GitHub Actions are defined using YAML. There are two main parts that needs to be defined, consisting of when the action should run, and then what should occur when the action is triggered. To start out, lets create a .github directory in the outermost directory of your repository, followed by a workflows directory within the .github one. Then create a main.yml file, which is where the action will be defined.","title":"The Action"},{"location":"blog/MkDocsCD/#when-to-run-the-action","text":"I am using this action to update my personal portfolio site as well as some other repositories that only hold documentation and GitHub Pages content. Therefore, I want this action to update with any push or pull request into the master branch. We define this with the following: on: push: branches: [master] pull_request: branches: [master]","title":"When to Run The Action"},{"location":"blog/MkDocsCD/#defining-the-jobs-and-steps","text":"After we decide when we want GitHub to run the action, the next step is to define the jobs and steps that need to occur in each job. For this, we will only have one job, called build. The tasks will be as follows: Checkout the master branch - this uses a built-in action available to all GitHub Actions to clone the repository into the newly spun-up container. Setup Python 3.7 - this also uses a built-in action that is available to all GitHub Actions. Install pip and mkdocs-material - the run keyword is used for terminal commands that you wish to use. the pip install mkdocs-material also automatically installs mkdocs and any other package dependencies needed. Run mkdocs gh-deploy - this builds the files and deploys them to GitHub pages. The full result can be seen below: name: Build Documentation using MkDocs # Controls when the action will run. Triggers the workflow on push or pull request # events but only for the master branch on: push: branches: [master] pull_request: branches: [master] jobs: build: name: Build and Deploy Documentation runs-on: ubuntu-latest steps: - name: Checkout Master uses: actions/checkout@v2 - name: Set up Python 3.7 uses: actions/setup-python@v2 with: python-version: '3.x' - name: Install dependencies run: | python -m pip install --upgrade pip pip install mkdocs-material - name: Deploy run: | git pull mkdocs gh-deploy","title":"Defining The Jobs and Steps"},{"location":"blog/MkDocsCD/#conclusion","text":"After creating the file above in the .github/workflows directory, that should be it! Simply commit your changes locally and push to the GitHub repository. You can view the status of the build on the Actions tab on your repository's GitHub page.","title":"Conclusion"},{"location":"blog/doYouReallyNeedTrashCans/","text":"Do You Really Need Trash Cans? February 26, 2020 The 2019\u20132020 MLB off-season was dominated by the revelation that the Houston Astros stole opposing pitcher\u2019s signs during their 2017 World Series-winning season. This was accomplished by looking at a live camera feed from center field in an area just off the dugout and communicating the next pitch to the batter by banging on a trash can. This got me thinking, \u201cCould machine learning predict what pitch was coming next? Do you even need to be stealing signs, or just a computer?\u201d Photo by Lesly Juarez on Unsplash The Astros Scheme The Astros scheme has been very well covered by now. I won\u2019t delve into the specifics of their cheating, but two specific things are relevant to the goal of predicting the next pitch with machine learning. First, they only seemed to bang the trash can if the next pitch wasn\u2019t going to be a fastball. This means they were not specifying what specific type of pitch it was, but only communicating if the pitch was going to be off-speed. Second is that Rob Arthur from Baseball Prospectus determined that the Astros correctly determined that a non-fastball was coming towards the plate 93% of the time. \u201cBy and large, the Astros tended to get the signals right, but it was hardly perfect. They were most accurate when they whacked the can: When they did so, a non-fastball was on the way 93 percent of the time and they were wrong seven percent of the time. \u2026 Based on Adams\u2019 data, the Astros used the trash can frequently and they were relatively accurate, moreso when banging than when silent.\u201d (Source: https://blogs.fangraphs.com/the-most-important-bangs-of-the-astros-scheme/) So, in order for our machine learning model to be comparable to the Astros\u2019 scheme, it must predict between fastball and non-fastball pitches, and do so with a pretty high degree of accuracy. The Data The great thing about applying analytics and machine learning to baseball is that there is a wealth of data freely available and easily accessible. Since I am using Python, I opted to use the pybaseball Python package, which provides a wrapper for Statcast data, which has entries of every pitch thrown in the MLB, including the game state, such as the inning, who is on base, and what the current count is. Also included are what hand the pitcher throws with and the hitter\u2019s stance. Crucially, Statcast also provides what type of pitch is thrown and its velocity. From this, I created a previous pitch and previous pitch velocity column. Once the data was pulled from Statcast and massaged a bit, I split it into a training and testing set. A problem that came up during the training process was that the dominant pitch in baseball is the fastball, and therefore there were many more cases of pitchers throwing a fastball then there was of pitchers throwing non-fastballs. This imbalance meant that the machine learning algorithms achieved very good accuracy by predicting the next pitch was always going to be a fastball. Obviously this isn\u2019t very helpful, so to counter this I used SMOTE to create synthetic non-fastball training data, leaving us with a balanced training dataset between all different types of pitches. In this analysis, we will use two different datasets, one consisting of Jose Berrios\u2019 pitches from the beginning of the 2017 season through the end of the 2019 season, and a set of all pitches thrown in every MLB game between April 1st, 2019 and April 7th, 2019. These two datasets will allow us to see if individual pitchers\u2019 habits are easier to predict compared to league-wide preferences on deciding what pitch to throw in a given situation. With these two different datasets, I also created a version of each that only contains if the pitch thrown was a fastball or a non-fastball. For this version of the data, I considered four-seam fastballs, two-seam fastballs, and cutters as \u201cfastballs\u201d and everything else as a non-fastball. I am taking an educated guess here that this is what the Astros considered a fastball as well. The Models I started with some \u201cbasic\u201d machine learning models such as Decision Trees, SVMs and k-Nearest Neighbors. These models all had abysmal accuracy (lower than 50%) on all datasets. I then decided to feed the data into two different neural networks: one for each version of the dataset. The Jose Berrios Models These models achieved better accuracy than our other approaches, with the multi-pitch classifier achieving 74% accuracy on the test set, and the fastball/no-fastball classifier achieving 58% accuracy. It is unclear to me why there is such a discrepancy between these two classifiers, but lets dive into the confusion matrices they produced. Looking at the confusion matrix above, we can see how many of the pitches of a given type matched the predicted type by looking at the diagonal of the matrix. For example, the model correctly predicted 52% of the curveballs thrown. Looking across the rows of the matrix tells you what percentage of the true pitch were misclassified as a different type of pitch. Looking at the curveball row (labelled \u201cCU\u201d), we can see that 52% the model predicted successfully, while 20% of the time it predicted that a changeup was going to be the next pitch. A two-seam fastball was the next most predicted at 18% of the time, followed by a four-seam fastball at about 10% of the time. If you turned this into banging on a trash can, about 30% of the time you would be wrong. While the true accuracy of this model was pretty good, turning its predictions into actionable results would be difficult, and is still far behind the Astros\u2019 accuracy. Above is the confusion matrix for the fastball/non-fastball classifier. As you can see, our true positive and true negative rate was very similar, which leads us to the accuracy of about 58%. Unlike the multi-pitch classifier, the outcome was relatively balanced. This is a good thing, as we want to reduce both the number of false positives and false negatives, but both of these percentages result in a worse outcome for our trash can banger: only about 60% of the time they would be correct. Maybe our league-wide data will fare better? The League-Wide Models The league-wide classifier for all pitches was 88% accurate on the testing set, but as before, let's look at the confusion matrix below: As you can see, there isn\u2019t that much improvement in terms of improving the trash-can bang\u2019s accuracy compared to the pitcher-specific model. The model predicts correctly that a four-seam fastball is going to be thrown 43% of the time it actually is, with it predicting that a curveball or a slider is going to be thrown about 20% of the time. Including a two-seam fastball\u2019s prediction gets us to correctly predicting that the pitch is going to be either a four or two-seam fastball is only about 51%. Clearly still not good enough accuracy for the batters to gain any benefit from the model. Maybe the fastball/non-fastball classifier will produce better results this time? So, obviously this isn\u2019t a great outcome either. The test set accuracy was 57%, and as the confusion matrix shows, the number of false positives was extremely high. This means that our trash-can would bang 54% of the time there was a fastball coming, when it is only supposed to bang on a non-fastball pitch. The classifier did a slightly better job predicting when a non-fastball was coming, but still had a false negative rate of 32%. This means that the trash can wouldn\u2019t be banged 32% of the time a non-fastball was pitched. This model would be of absolutely no help to the batter. Conclusion Coming into this project, I thought that machine learning might be able to predict what the next pitch would be to a high enough accuracy where it might be beneficial to a batter. This is obviously not the case. Even with some models producing an accuracy of greater than 75%, the false positive and false negative rates are great enough that there would be no discernible benefit. Different architectures of neural networks and more data surrounding each pitch could possibly produce better accuracy, but I\u2019m now skeptical if it would help that much. For now, however, the best way to know what the next pitch will be is to cheat. Checkout the code here: https://github.com/parkererickson/baseballDataScience/blob/master/nextPitchPrediction.ipynb","title":"Do You Really Need Trash Cans?"},{"location":"blog/doYouReallyNeedTrashCans/#do-you-really-need-trash-cans","text":"February 26, 2020 The 2019\u20132020 MLB off-season was dominated by the revelation that the Houston Astros stole opposing pitcher\u2019s signs during their 2017 World Series-winning season. This was accomplished by looking at a live camera feed from center field in an area just off the dugout and communicating the next pitch to the batter by banging on a trash can. This got me thinking, \u201cCould machine learning predict what pitch was coming next? Do you even need to be stealing signs, or just a computer?\u201d Photo by Lesly Juarez on Unsplash","title":"Do You Really Need Trash Cans?"},{"location":"blog/doYouReallyNeedTrashCans/#the-astros-scheme","text":"The Astros scheme has been very well covered by now. I won\u2019t delve into the specifics of their cheating, but two specific things are relevant to the goal of predicting the next pitch with machine learning. First, they only seemed to bang the trash can if the next pitch wasn\u2019t going to be a fastball. This means they were not specifying what specific type of pitch it was, but only communicating if the pitch was going to be off-speed. Second is that Rob Arthur from Baseball Prospectus determined that the Astros correctly determined that a non-fastball was coming towards the plate 93% of the time. \u201cBy and large, the Astros tended to get the signals right, but it was hardly perfect. They were most accurate when they whacked the can: When they did so, a non-fastball was on the way 93 percent of the time and they were wrong seven percent of the time. \u2026 Based on Adams\u2019 data, the Astros used the trash can frequently and they were relatively accurate, moreso when banging than when silent.\u201d (Source: https://blogs.fangraphs.com/the-most-important-bangs-of-the-astros-scheme/) So, in order for our machine learning model to be comparable to the Astros\u2019 scheme, it must predict between fastball and non-fastball pitches, and do so with a pretty high degree of accuracy.","title":"The Astros Scheme"},{"location":"blog/doYouReallyNeedTrashCans/#the-data","text":"The great thing about applying analytics and machine learning to baseball is that there is a wealth of data freely available and easily accessible. Since I am using Python, I opted to use the pybaseball Python package, which provides a wrapper for Statcast data, which has entries of every pitch thrown in the MLB, including the game state, such as the inning, who is on base, and what the current count is. Also included are what hand the pitcher throws with and the hitter\u2019s stance. Crucially, Statcast also provides what type of pitch is thrown and its velocity. From this, I created a previous pitch and previous pitch velocity column. Once the data was pulled from Statcast and massaged a bit, I split it into a training and testing set. A problem that came up during the training process was that the dominant pitch in baseball is the fastball, and therefore there were many more cases of pitchers throwing a fastball then there was of pitchers throwing non-fastballs. This imbalance meant that the machine learning algorithms achieved very good accuracy by predicting the next pitch was always going to be a fastball. Obviously this isn\u2019t very helpful, so to counter this I used SMOTE to create synthetic non-fastball training data, leaving us with a balanced training dataset between all different types of pitches. In this analysis, we will use two different datasets, one consisting of Jose Berrios\u2019 pitches from the beginning of the 2017 season through the end of the 2019 season, and a set of all pitches thrown in every MLB game between April 1st, 2019 and April 7th, 2019. These two datasets will allow us to see if individual pitchers\u2019 habits are easier to predict compared to league-wide preferences on deciding what pitch to throw in a given situation. With these two different datasets, I also created a version of each that only contains if the pitch thrown was a fastball or a non-fastball. For this version of the data, I considered four-seam fastballs, two-seam fastballs, and cutters as \u201cfastballs\u201d and everything else as a non-fastball. I am taking an educated guess here that this is what the Astros considered a fastball as well.","title":"The Data"},{"location":"blog/doYouReallyNeedTrashCans/#the-models","text":"I started with some \u201cbasic\u201d machine learning models such as Decision Trees, SVMs and k-Nearest Neighbors. These models all had abysmal accuracy (lower than 50%) on all datasets. I then decided to feed the data into two different neural networks: one for each version of the dataset.","title":"The Models"},{"location":"blog/doYouReallyNeedTrashCans/#the-jose-berrios-models","text":"These models achieved better accuracy than our other approaches, with the multi-pitch classifier achieving 74% accuracy on the test set, and the fastball/no-fastball classifier achieving 58% accuracy. It is unclear to me why there is such a discrepancy between these two classifiers, but lets dive into the confusion matrices they produced. Looking at the confusion matrix above, we can see how many of the pitches of a given type matched the predicted type by looking at the diagonal of the matrix. For example, the model correctly predicted 52% of the curveballs thrown. Looking across the rows of the matrix tells you what percentage of the true pitch were misclassified as a different type of pitch. Looking at the curveball row (labelled \u201cCU\u201d), we can see that 52% the model predicted successfully, while 20% of the time it predicted that a changeup was going to be the next pitch. A two-seam fastball was the next most predicted at 18% of the time, followed by a four-seam fastball at about 10% of the time. If you turned this into banging on a trash can, about 30% of the time you would be wrong. While the true accuracy of this model was pretty good, turning its predictions into actionable results would be difficult, and is still far behind the Astros\u2019 accuracy. Above is the confusion matrix for the fastball/non-fastball classifier. As you can see, our true positive and true negative rate was very similar, which leads us to the accuracy of about 58%. Unlike the multi-pitch classifier, the outcome was relatively balanced. This is a good thing, as we want to reduce both the number of false positives and false negatives, but both of these percentages result in a worse outcome for our trash can banger: only about 60% of the time they would be correct. Maybe our league-wide data will fare better?","title":"The Jose Berrios Models"},{"location":"blog/doYouReallyNeedTrashCans/#the-league-wide-models","text":"The league-wide classifier for all pitches was 88% accurate on the testing set, but as before, let's look at the confusion matrix below: As you can see, there isn\u2019t that much improvement in terms of improving the trash-can bang\u2019s accuracy compared to the pitcher-specific model. The model predicts correctly that a four-seam fastball is going to be thrown 43% of the time it actually is, with it predicting that a curveball or a slider is going to be thrown about 20% of the time. Including a two-seam fastball\u2019s prediction gets us to correctly predicting that the pitch is going to be either a four or two-seam fastball is only about 51%. Clearly still not good enough accuracy for the batters to gain any benefit from the model. Maybe the fastball/non-fastball classifier will produce better results this time? So, obviously this isn\u2019t a great outcome either. The test set accuracy was 57%, and as the confusion matrix shows, the number of false positives was extremely high. This means that our trash-can would bang 54% of the time there was a fastball coming, when it is only supposed to bang on a non-fastball pitch. The classifier did a slightly better job predicting when a non-fastball was coming, but still had a false negative rate of 32%. This means that the trash can wouldn\u2019t be banged 32% of the time a non-fastball was pitched. This model would be of absolutely no help to the batter.","title":"The League-Wide Models"},{"location":"blog/doYouReallyNeedTrashCans/#conclusion","text":"Coming into this project, I thought that machine learning might be able to predict what the next pitch would be to a high enough accuracy where it might be beneficial to a batter. This is obviously not the case. Even with some models producing an accuracy of greater than 75%, the false positive and false negative rates are great enough that there would be no discernible benefit. Different architectures of neural networks and more data surrounding each pitch could possibly produce better accuracy, but I\u2019m now skeptical if it would help that much. For now, however, the best way to know what the next pitch will be is to cheat. Checkout the code here: https://github.com/parkererickson/baseballDataScience/blob/master/nextPitchPrediction.ipynb","title":"Conclusion"},{"location":"blog/gettingStartedWithMkdocs/","text":"Getting Started with MkDocs May 26, 2020 Good documentation is what makes a project great. I was recently introduced to a new way to create documentation, MkDocs, and have since created a documentation site for my open-source project pyTigerGraph , as well as updating my personal portfolio page to it. MkDocs is a really easy way to create great looking documentation, only using markdown and a couple configuration files. To make things even better, you can easily deploy the hosting of these documents to GitHub pages. Installation and Getting Started First, make sure you have Python and pip installed. The simply run: pip install mkdocs . Once this is done, it is time to create our new MkDocs project. For a documenting a project, you probably want all the documentation to reside inside the main directory of the project. To do this, open a terminal to that directory, and then run mkdocs new my-project where my-project is the project name that you desire. This will then create a new folder named after whatever the project name is. You want to then take the contents out of this folder, and move them into your project folder. Therefore, you should have a project file structure like this: project - |- docs - | |- index.md | |- anyothermarkdownfiles.md | |_ stylesheets - (this has to be created) | |_ extra.css (this has to be created) | |-mkdocs.yml | |- other project files To make sure that this works, simply run mkdocs serve in your terminal and open up 127.0.0.1:8000 in your web browser. It should show something like this: Screenshot from MkDocs documentation You can then edit the index.md page that was automatically generated with your homepage content. Saving the markdown files tracked by MkDocs automatically refreshes the preview server that is locally hosted. Adding Pages After editing your homepage, you probably want to add other pages to your documentation. To do this, we open up the mkdocs.yml file. Initially, it probably looks somthing like this: site_name: MkLorum nav: - Home: index.md You can change the site name by simply changing the site_name parameter in the file. To add another page, create a new markdown file, such as gettingStarted.md . Then, we will add it to the YAML file like this: site_name: MkLorum nav: - Home: index.md - Getting Started: gettingStarted.md Follow this process for any other files that you want included on the webpage. Choose Your Theme Personally, I don't like the default website theme provided by MkDocs. For both my personal and project page, I opted for the material theme. To use this theme, run pip install mkdocs-material , and add this to your mkdocs.yml file: theme: name: material Other themes can be viewed here . The customization step below might work on different themes, but has not been tested. Customize To change the color of the theme, we will create a CSS file. In the YAML file, we need to declare that we want to use this file, done by: extra_css: - stylesheets/extra.css Then we need to create the stylesheets folder, inside of the docs folder. Then we will create the extra.css file. This file will look like this: :root { /* Primary color shades */ --md-primary-fg-color: #7A0019; --md-primary-fg-color--light: #ffffff; --md-primary-fg-color--dark: #7A0019; --md-primary-bg-color: #ffffff; --md-primary-bg-color--light: #ffffff; --md-text-link-color: #7A0019; /* Accent color shades */ --md-accent-fg-color: #7A0019; --md-accent-fg-color--transparent: #7A0019; --md-accent-bg-color: #7A0019; --md-accent-bg-color--light: #7A0019; } This file is where you can define any sort of custom color scheme. In the case above, it is maroon and white. With the material theme, we can also add a logo and favicon to our site. This can be done by adding under the theme area in mkdocs.yml : theme: name: material logo: https://avatars1.githubusercontent.com/u/9616171?s=460&v=4 favicon: https://avatars1.githubusercontent.com/u/9616171?s=460&v=4 This adds my GitHub profile picture to the site, but it could also be an image found within the repository. We can also add the status of the desired repository. To do this, simply add repo_url: REPO_NAME_HERE to mkdocs.yml . My personal portfolio website also contains links to various social media platforms at the bottom. Add this to your mkdocs.yml : extra: social: - icon: fontawesome/brands/github link: https://github.com/parkererickson - icon: fontawesome/brands/twitter link: https://twitter.com/p_erickson30 - icon: fontawesome/brands/linkedin link: https://linkedin.com/in/parker-erickson - icon: fontawesome/brands/medium link: https://medium.com/@parker.erickson In total, your mkdocs.yml should look something like this: site_name: Parker Erickson nav: - 'Home': index.md - 'Projects': projects.md - 'Blog': - 'Getting Started with MkDocs': blog/gettingStartedWithMkdocs.md - 'IPO Prediction Using Graph Convolutional Neural Networks': blog/ipoGCN.md - 'Do You Really Need Trash Cans?': blog/doYouReallyNeedTrashCans.md theme: name: material logo: https://avatars1.githubusercontent.com/u/9616171?s=460&v=4 favicon: https://avatars1.githubusercontent.com/u/9616171?s=460&v=4 extra: social: - icon: fontawesome/brands/github link: https://github.com/parkererickson - icon: fontawesome/brands/twitter link: https://twitter.com/p_erickson30 - icon: fontawesome/brands/linkedin link: https://linkedin.com/in/parker-erickson - icon: fontawesome/brands/medium link: https://medium.com/@parker.erickson extra_css: - stylesheets/extra.css Deploy To deploy to GitHub pages, make sure you have a GitHub repository initialized and properly setup. Then, make sure to add site/ to your .gitignore . Then, simply run mkdocs gh-deploy . This should create a new branch in your repository, compile your Markdown and other files into HTML and CSS, and enable GitHub Pages to host it. After a while, you should be able to go to YOUR-ORGANIZATION-NAME.github.io/YOUR-REPO-NAME to view the completed documentation.","title":"Getting Started with MkDocs"},{"location":"blog/gettingStartedWithMkdocs/#getting-started-with-mkdocs","text":"May 26, 2020 Good documentation is what makes a project great. I was recently introduced to a new way to create documentation, MkDocs, and have since created a documentation site for my open-source project pyTigerGraph , as well as updating my personal portfolio page to it. MkDocs is a really easy way to create great looking documentation, only using markdown and a couple configuration files. To make things even better, you can easily deploy the hosting of these documents to GitHub pages.","title":"Getting Started with MkDocs"},{"location":"blog/gettingStartedWithMkdocs/#installation-and-getting-started","text":"First, make sure you have Python and pip installed. The simply run: pip install mkdocs . Once this is done, it is time to create our new MkDocs project. For a documenting a project, you probably want all the documentation to reside inside the main directory of the project. To do this, open a terminal to that directory, and then run mkdocs new my-project where my-project is the project name that you desire. This will then create a new folder named after whatever the project name is. You want to then take the contents out of this folder, and move them into your project folder. Therefore, you should have a project file structure like this: project - |- docs - | |- index.md | |- anyothermarkdownfiles.md | |_ stylesheets - (this has to be created) | |_ extra.css (this has to be created) | |-mkdocs.yml | |- other project files To make sure that this works, simply run mkdocs serve in your terminal and open up 127.0.0.1:8000 in your web browser. It should show something like this: Screenshot from MkDocs documentation You can then edit the index.md page that was automatically generated with your homepage content. Saving the markdown files tracked by MkDocs automatically refreshes the preview server that is locally hosted.","title":"Installation and Getting Started"},{"location":"blog/gettingStartedWithMkdocs/#adding-pages","text":"After editing your homepage, you probably want to add other pages to your documentation. To do this, we open up the mkdocs.yml file. Initially, it probably looks somthing like this: site_name: MkLorum nav: - Home: index.md You can change the site name by simply changing the site_name parameter in the file. To add another page, create a new markdown file, such as gettingStarted.md . Then, we will add it to the YAML file like this: site_name: MkLorum nav: - Home: index.md - Getting Started: gettingStarted.md Follow this process for any other files that you want included on the webpage.","title":"Adding Pages"},{"location":"blog/gettingStartedWithMkdocs/#choose-your-theme","text":"Personally, I don't like the default website theme provided by MkDocs. For both my personal and project page, I opted for the material theme. To use this theme, run pip install mkdocs-material , and add this to your mkdocs.yml file: theme: name: material Other themes can be viewed here . The customization step below might work on different themes, but has not been tested.","title":"Choose Your Theme"},{"location":"blog/gettingStartedWithMkdocs/#customize","text":"To change the color of the theme, we will create a CSS file. In the YAML file, we need to declare that we want to use this file, done by: extra_css: - stylesheets/extra.css Then we need to create the stylesheets folder, inside of the docs folder. Then we will create the extra.css file. This file will look like this: :root { /* Primary color shades */ --md-primary-fg-color: #7A0019; --md-primary-fg-color--light: #ffffff; --md-primary-fg-color--dark: #7A0019; --md-primary-bg-color: #ffffff; --md-primary-bg-color--light: #ffffff; --md-text-link-color: #7A0019; /* Accent color shades */ --md-accent-fg-color: #7A0019; --md-accent-fg-color--transparent: #7A0019; --md-accent-bg-color: #7A0019; --md-accent-bg-color--light: #7A0019; } This file is where you can define any sort of custom color scheme. In the case above, it is maroon and white. With the material theme, we can also add a logo and favicon to our site. This can be done by adding under the theme area in mkdocs.yml : theme: name: material logo: https://avatars1.githubusercontent.com/u/9616171?s=460&v=4 favicon: https://avatars1.githubusercontent.com/u/9616171?s=460&v=4 This adds my GitHub profile picture to the site, but it could also be an image found within the repository. We can also add the status of the desired repository. To do this, simply add repo_url: REPO_NAME_HERE to mkdocs.yml . My personal portfolio website also contains links to various social media platforms at the bottom. Add this to your mkdocs.yml : extra: social: - icon: fontawesome/brands/github link: https://github.com/parkererickson - icon: fontawesome/brands/twitter link: https://twitter.com/p_erickson30 - icon: fontawesome/brands/linkedin link: https://linkedin.com/in/parker-erickson - icon: fontawesome/brands/medium link: https://medium.com/@parker.erickson In total, your mkdocs.yml should look something like this: site_name: Parker Erickson nav: - 'Home': index.md - 'Projects': projects.md - 'Blog': - 'Getting Started with MkDocs': blog/gettingStartedWithMkdocs.md - 'IPO Prediction Using Graph Convolutional Neural Networks': blog/ipoGCN.md - 'Do You Really Need Trash Cans?': blog/doYouReallyNeedTrashCans.md theme: name: material logo: https://avatars1.githubusercontent.com/u/9616171?s=460&v=4 favicon: https://avatars1.githubusercontent.com/u/9616171?s=460&v=4 extra: social: - icon: fontawesome/brands/github link: https://github.com/parkererickson - icon: fontawesome/brands/twitter link: https://twitter.com/p_erickson30 - icon: fontawesome/brands/linkedin link: https://linkedin.com/in/parker-erickson - icon: fontawesome/brands/medium link: https://medium.com/@parker.erickson extra_css: - stylesheets/extra.css","title":"Customize"},{"location":"blog/gettingStartedWithMkdocs/#deploy","text":"To deploy to GitHub pages, make sure you have a GitHub repository initialized and properly setup. Then, make sure to add site/ to your .gitignore . Then, simply run mkdocs gh-deploy . This should create a new branch in your repository, compile your Markdown and other files into HTML and CSS, and enable GitHub Pages to host it. After a while, you should be able to go to YOUR-ORGANIZATION-NAME.github.io/YOUR-REPO-NAME to view the completed documentation.","title":"Deploy"},{"location":"blog/ipoGCN/","text":"Predicting Initial Public Offerings Using Graph Convolutional Neural Networks May 20th, 2020 About a year ago, I was introduced to the concept of graph databases, and how they represent data differently compared to a tabular, relational database. I was fascinated that there was a way to store and find relationships in data in a manner that I found more intuitive instead of computing JOINs on tabular data. If two pieces of data are related, in a graph database, you simply create an edge between them. Since the data is in a graph, you can perform all the standard graph algorithms on your database, such as breadth and depth-first search, shortest path algorithms, and similarity algorithms. All of these algorithms work off the edges (relationships) between the various data points. Turns out, there are machine learning algorithms that also work with the relationships between the data. This article will walk through the steps to get your own graph machine learning pipeline up and running \u2014 from database to predictions. Photo by Rick Tap on Unsplash First, we will set up a TigerGraph Cloud instance with an example dataset from Crunchbase. This data has about 200,000 companies in various stages of funding, and contains information such as if they have achieved an Initial Public Offering (IPO), the key investors of the company, the founders, their headquarters location, etc. We will then connect to the database using pyTigerGraph and Giraffle inside of a Jupyter Notebook. Finally, we will set up a Graph Convolutional Neural Network (GCN) to predict whether a given company in our dataset will IPO. To follow along with the code, check out the repository here. Setting Up TigerGraph Cloud I\u2019m not going to go that in-depth with setting up a TigerGraph Cloud instance, as this article does a really good job walking you through the steps of provisioning an instance. On step 1, simply choose the \u201cEnterprise Knowledge Graph (Crunchbase)\u201d starter kit. Once you have your starter kit up and running, we will have to get a SSL certificate to access the server via Gradle. In your project directory, type this into your terminal: openssl s_client -connect <YOUR_HOSTNAME_HERE>.i.tgcloud.io:14240 < /dev/null 2> /dev/null | \\ openssl x509 -text > cert.txt We also need to create two other files. First, lets create a gradle-local.properties file in the base project directory. This should contain: gsqlHost=YOUR_HOSTNAME_HERE.i.tgcloud.io gsqlUserName=tigergraph gsqlPassword=YOUR_PASSWORD_HERE gsqlAdminUserName=tigergraph gsqlAdminPassword=YOUR_PASSWORD_HERE gsqlCaCert=./cert.txt The other should be placed in the py_scripts/ directory and be named cfg.py. This should contain: secret = \"YOUR_SECRET_HERE\" token = \"\" password = \"YOUR_PASSWORD_HERE\" The secret key can be obtained in Graph Studio under the admin page. Installing Queries and Pulling Data We will use two different tools to interface with our TigerGraph cloud instance: Giraffle and pyTigerGraph. Giraffle will allow us to install queries we need to run on the database, while pyTigerGraph will provide an interface for us to pull the results of those queries into Python. Giraffle Giraffle is a plugin for Gradle, a build system. This allows you to easily package up code to be deployed on various different platforms and use version control software such as Git to keep track of the queries you write for the database. For more information, check out its project page here. The Queries We install the queries in the first few cells of the Jupyter Notebook through a couple of terminal commands. What each query does is outlined below: - companyLinks computes relationships between companies in TigerGraph and returns them in a JSON payload that we can parse with Python. This oversimplifies the graph here. The query returns pairs of companies that have something in common. This hurts accuracy, as some common elements (founders, investors, etc.) might be more important than location or industry. It is possible to create a GCN that has multiple types of vertices, (known as a Relational Graph Convolutional Notebook) but it is more complex. A good way to get started is to simplify the graph until you only have relations between the same type of thing. - getAllCompanies does exactly what the name implies \u2014 it returns a list of all companies found in the dataset. The reason why we need this will become apparent in the next section. - getAllIpo gets all the companies that have IPOed found in the dataset. This is useful in the next section, as well as checking our accuracy of predictions. pyTigerGraph In order to get the results from the queries we installed, we will use pyTigerGraph. For more information, check out the package on my GitHub here. Undersampling Data Alright, now that we got all of the queries installed and the data pulled into our notebook, notice a few things. First, the number of IPOed companies is minuscule (about 1,200) compared to the total number of companies (about 200,000). This means that the dataset is extremely unbalanced, and that will lead to the GCN predicting every company not to IPO (that way it would be 99.4% accurate). Another thing to take into account is that most computers will not have enough memory to run a GCN on the full graph. Conveniently, the unbalanced data means that we should undersample the non-IPOed companies in order to make a more evenly balanced dataset. This results in a graph that has about 2,000 vertices, evenly split between companies that have IPOed and ones that have not. There is a drawback to this approach, however. Since these companies are randomly sampled from the non-IPOed and IPOed list, we cannot guarantee that there are many edges between each company, which hurts our accuracy quite a bit. The Graph Convolutional Neural Network Classification using a Graph Convolutional Neural Network (Source: https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html) A Graph Convolutional Neural Network (GCN) is a semi-supervised classification algorithm that works off of the connections in the graph, as well as the features of each vertex. The concept is similar to a traditional image-based convolutional neural network, but instead of looking at adjacent pixels, the GCN looks at vertices that are connected via an edge. The vertex features can be any vector, such as a doc2vec representation of the various attributes of the vertex, or simply just a one-hot encoded vector, which is what I chose to do here. We then label two different vertices, one that is known to have IPOed and another that hasn\u2019t. Our neural network architecture is pretty straight forward. It consists of two layers, with an input dimension equal to the number of entries in the feature vector (it also happens to be the number of vertices in the graph since we one-hot encoded them). We then pass the input through a layer with 32 neurons, and then out through 2 neurons that will provide our output. We use Adam as our optimizer for the training process. We then begin the training loop. Unfortunately, due to our undersampling of the graph earlier, the GCN does not always have enough edges in the graph to reliably make predictions accurately. I usually get about 60% accuracy, but it does vary quite a bit due to the random sample of companies. Conclusion The GCN is not a great method to predict if a company will IPO or not, due to the memory constraints and the need for undersampling the graph. Other graph machine learning methods, such as node2vec might fair better. Another way that accuracy might improve is using a relational graph convolutional neural network (R-GCN) which would work on graphs with multiple different types of vertices. Credits Article and notebook written by Parker Erickson, a student at the University of Minnesota pursuing a B.S. in Computer Science. His interests include graph databases, machine learning, traveling, playing the saxophone, and watching Minnesota Twins baseball. Feel free to reach out! Find him at: LinkedIn: https://www.linkedin.com/in/parker-erickson/ GitHub: https://github.com/parkererickson Email: parker.erickson30@gmail.com GCN Resources: DGL Documentation: https://docs.dgl.ai/ GCN paper by Kipf and Welling https://arxiv.org/abs/1609.02907 R-GCN paper: https://arxiv.org/abs/1703.06103 Notebook adapted from: https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html","title":"IPO Prediction Using Graph Convolutional Neural Networks"},{"location":"blog/ipoGCN/#predicting-initial-public-offerings-using-graph-convolutional-neural-networks","text":"May 20th, 2020 About a year ago, I was introduced to the concept of graph databases, and how they represent data differently compared to a tabular, relational database. I was fascinated that there was a way to store and find relationships in data in a manner that I found more intuitive instead of computing JOINs on tabular data. If two pieces of data are related, in a graph database, you simply create an edge between them. Since the data is in a graph, you can perform all the standard graph algorithms on your database, such as breadth and depth-first search, shortest path algorithms, and similarity algorithms. All of these algorithms work off the edges (relationships) between the various data points. Turns out, there are machine learning algorithms that also work with the relationships between the data. This article will walk through the steps to get your own graph machine learning pipeline up and running \u2014 from database to predictions. Photo by Rick Tap on Unsplash First, we will set up a TigerGraph Cloud instance with an example dataset from Crunchbase. This data has about 200,000 companies in various stages of funding, and contains information such as if they have achieved an Initial Public Offering (IPO), the key investors of the company, the founders, their headquarters location, etc. We will then connect to the database using pyTigerGraph and Giraffle inside of a Jupyter Notebook. Finally, we will set up a Graph Convolutional Neural Network (GCN) to predict whether a given company in our dataset will IPO. To follow along with the code, check out the repository here.","title":"Predicting Initial Public Offerings Using Graph Convolutional Neural Networks"},{"location":"blog/ipoGCN/#setting-up-tigergraph-cloud","text":"I\u2019m not going to go that in-depth with setting up a TigerGraph Cloud instance, as this article does a really good job walking you through the steps of provisioning an instance. On step 1, simply choose the \u201cEnterprise Knowledge Graph (Crunchbase)\u201d starter kit. Once you have your starter kit up and running, we will have to get a SSL certificate to access the server via Gradle. In your project directory, type this into your terminal: openssl s_client -connect <YOUR_HOSTNAME_HERE>.i.tgcloud.io:14240 < /dev/null 2> /dev/null | \\ openssl x509 -text > cert.txt We also need to create two other files. First, lets create a gradle-local.properties file in the base project directory. This should contain: gsqlHost=YOUR_HOSTNAME_HERE.i.tgcloud.io gsqlUserName=tigergraph gsqlPassword=YOUR_PASSWORD_HERE gsqlAdminUserName=tigergraph gsqlAdminPassword=YOUR_PASSWORD_HERE gsqlCaCert=./cert.txt The other should be placed in the py_scripts/ directory and be named cfg.py. This should contain: secret = \"YOUR_SECRET_HERE\" token = \"\" password = \"YOUR_PASSWORD_HERE\" The secret key can be obtained in Graph Studio under the admin page.","title":"Setting Up TigerGraph Cloud"},{"location":"blog/ipoGCN/#installing-queries-and-pulling-data","text":"We will use two different tools to interface with our TigerGraph cloud instance: Giraffle and pyTigerGraph. Giraffle will allow us to install queries we need to run on the database, while pyTigerGraph will provide an interface for us to pull the results of those queries into Python. Giraffle Giraffle is a plugin for Gradle, a build system. This allows you to easily package up code to be deployed on various different platforms and use version control software such as Git to keep track of the queries you write for the database. For more information, check out its project page here.","title":"Installing Queries and Pulling Data"},{"location":"blog/ipoGCN/#the-queries","text":"We install the queries in the first few cells of the Jupyter Notebook through a couple of terminal commands. What each query does is outlined below: - companyLinks computes relationships between companies in TigerGraph and returns them in a JSON payload that we can parse with Python. This oversimplifies the graph here. The query returns pairs of companies that have something in common. This hurts accuracy, as some common elements (founders, investors, etc.) might be more important than location or industry. It is possible to create a GCN that has multiple types of vertices, (known as a Relational Graph Convolutional Notebook) but it is more complex. A good way to get started is to simplify the graph until you only have relations between the same type of thing. - getAllCompanies does exactly what the name implies \u2014 it returns a list of all companies found in the dataset. The reason why we need this will become apparent in the next section. - getAllIpo gets all the companies that have IPOed found in the dataset. This is useful in the next section, as well as checking our accuracy of predictions.","title":"The Queries"},{"location":"blog/ipoGCN/#pytigergraph","text":"In order to get the results from the queries we installed, we will use pyTigerGraph. For more information, check out the package on my GitHub here.","title":"pyTigerGraph"},{"location":"blog/ipoGCN/#undersampling-data","text":"Alright, now that we got all of the queries installed and the data pulled into our notebook, notice a few things. First, the number of IPOed companies is minuscule (about 1,200) compared to the total number of companies (about 200,000). This means that the dataset is extremely unbalanced, and that will lead to the GCN predicting every company not to IPO (that way it would be 99.4% accurate). Another thing to take into account is that most computers will not have enough memory to run a GCN on the full graph. Conveniently, the unbalanced data means that we should undersample the non-IPOed companies in order to make a more evenly balanced dataset. This results in a graph that has about 2,000 vertices, evenly split between companies that have IPOed and ones that have not. There is a drawback to this approach, however. Since these companies are randomly sampled from the non-IPOed and IPOed list, we cannot guarantee that there are many edges between each company, which hurts our accuracy quite a bit.","title":"Undersampling Data"},{"location":"blog/ipoGCN/#the-graph-convolutional-neural-network","text":"Classification using a Graph Convolutional Neural Network (Source: https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html) A Graph Convolutional Neural Network (GCN) is a semi-supervised classification algorithm that works off of the connections in the graph, as well as the features of each vertex. The concept is similar to a traditional image-based convolutional neural network, but instead of looking at adjacent pixels, the GCN looks at vertices that are connected via an edge. The vertex features can be any vector, such as a doc2vec representation of the various attributes of the vertex, or simply just a one-hot encoded vector, which is what I chose to do here. We then label two different vertices, one that is known to have IPOed and another that hasn\u2019t. Our neural network architecture is pretty straight forward. It consists of two layers, with an input dimension equal to the number of entries in the feature vector (it also happens to be the number of vertices in the graph since we one-hot encoded them). We then pass the input through a layer with 32 neurons, and then out through 2 neurons that will provide our output. We use Adam as our optimizer for the training process. We then begin the training loop. Unfortunately, due to our undersampling of the graph earlier, the GCN does not always have enough edges in the graph to reliably make predictions accurately. I usually get about 60% accuracy, but it does vary quite a bit due to the random sample of companies.","title":"The Graph Convolutional Neural Network"},{"location":"blog/ipoGCN/#conclusion","text":"The GCN is not a great method to predict if a company will IPO or not, due to the memory constraints and the need for undersampling the graph. Other graph machine learning methods, such as node2vec might fair better. Another way that accuracy might improve is using a relational graph convolutional neural network (R-GCN) which would work on graphs with multiple different types of vertices.","title":"Conclusion"},{"location":"blog/ipoGCN/#credits","text":"Article and notebook written by Parker Erickson, a student at the University of Minnesota pursuing a B.S. in Computer Science. His interests include graph databases, machine learning, traveling, playing the saxophone, and watching Minnesota Twins baseball. Feel free to reach out! Find him at: LinkedIn: https://www.linkedin.com/in/parker-erickson/ GitHub: https://github.com/parkererickson Email: parker.erickson30@gmail.com GCN Resources: DGL Documentation: https://docs.dgl.ai/ GCN paper by Kipf and Welling https://arxiv.org/abs/1609.02907 R-GCN paper: https://arxiv.org/abs/1703.06103 Notebook adapted from: https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html","title":"Credits"}]}